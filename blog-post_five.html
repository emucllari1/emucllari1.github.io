<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>Edison's Blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" type="image/jpg" href="favicon.ico"/>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

    <!-- Template Google Fonts -->
    <link href="https://fonts.googleapis.com/css?family=Poppins:400,400i,500,500i,600,600i,700,700i,800,800i,900,900i" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,400i,600,600i,700" rel="stylesheet">

    <!-- Template CSS Files -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/preloader.min.css" rel="stylesheet">
    <link href="css/circle.css" rel="stylesheet">
    <link href="css/font-awesome.min.css" rel="stylesheet">
    <link href="css/fm.revealator.jquery.min.css" rel="stylesheet">
    <link href="css/style.css" rel="stylesheet">

    <!-- CSS Skin File -->
    <link href="css/skins/green.css" rel="stylesheet">

    <!-- Live Style Switcher - demo only -->
    <link rel="alternate stylesheet" type="text/css" title="blue" href="css/skins/blue.css" />
    <link rel="alternate stylesheet" type="text/css" title="green" href="css/skins/green.css" />
    <link rel="alternate stylesheet" type="text/css" title="yellow" href="css/skins/yellow.css" />
    <link rel="alternate stylesheet" type="text/css" title="blueviolet" href="css/skins/blueviolet.css" />
    <link rel="alternate stylesheet" type="text/css" title="goldenrod" href="css/skins/goldenrod.css" />
    <link rel="alternate stylesheet" type="text/css" title="magenta" href="css/skins/magenta.css" />
    <link rel="alternate stylesheet" type="text/css" title="orange" href="css/skins/orange.css" />
    <link rel="alternate stylesheet" type="text/css" title="purple" href="css/skins/purple.css" />
    <link rel="alternate stylesheet" type="text/css" title="red" href="css/skins/red.css" />
    <link rel="alternate stylesheet" type="text/css" title="yellowgreen" href="css/skins/yellowgreen.css" />
    <link rel="stylesheet" type="text/css" href="css/styleswitcher.css" />

    <script src="js/modernizr.custom.js"></script>

    <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']], // Delimiters for inline math
        displayMath: [['$$', '$$'], ['\\[', '\\]']], // Delimiters for display math
        processEscapes: true // Allows \$ to be treated as text
      },
      svg: {
        fontCache: 'global' // Improves rendering speed
      }
    };
    </script>
    <script id="MathJax-script" async
            src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>

<style>
    .cnn-highlight {
        background: #e3f2fd;
        border-left: 6px solid #1976d2;
        padding: 14px;
        margin: 24px 0;
        border-radius: 8px;
    }
    .cnn-formula {
        background: #fffde7;
        border-left: 6px solid #fbc02d;
        padding: 14px;
        margin: 24px 0;
        border-radius: 8px;
        font-size: 1.09em;
    }
    .cnn-tip {
        background: #e8f5e9;
        border-left: 6px solid #388e3c;
        padding: 14px;
        margin: 24px 0;
        border-radius: 8px;
    }
    .cnn-warning {
        background: #fff3e0;
        border-left: 6px solid #f57c00;
        padding: 14px;
        margin: 24px 0;
        border-radius: 8px;
    }
    .cnn-table {
        border-collapse: collapse;
        width: 100%;
        margin: 20px 0;
    }
    .cnn-table th, .cnn-table td {
        border: 1px solid #bdbdbd;
        padding: 10px;
        text-align: left;
    }
    .cnn-table th {
        background: #f0f4c3;
    }
    .cnn-table tr:nth-child(even) {
        background: #f9fbe7;
    }
</style>
</head>

<body class="blog-post light">
<!-- Live Style Switcher Starts - demo only -->
<div id="switcher" class="">
    <div class="content-switcher">
        <h4>STYLE SWITCHER</h4>
        <ul>
            <li>
                <a href="#" onclick="setActiveStyleSheet('purple');" title="purple" class="color"><img src="img/styleswitcher/purple.png" alt="purple"/></a>
            </li>
            <li>
                <a href="#" onclick="setActiveStyleSheet('red');" title="red" class="color"><img src="img/styleswitcher/red.png" alt="red"/></a>
            </li>
            <li>
                <a href="#" onclick="setActiveStyleSheet('blueviolet');" title="blueviolet" class="color"><img src="img/styleswitcher/blueviolet.png" alt="blueviolet"/></a>
            </li>
            <li>
                <a href="#" onclick="setActiveStyleSheet('blue');" title="blue" class="color"><img src="img/styleswitcher/blue.png" alt="blue"/></a>
            </li>
            <li>
                <a href="#" onclick="setActiveStyleSheet('goldenrod');" title="goldenrod" class="color"><img src="img/styleswitcher/goldenrod.png" alt="goldenrod"/></a>
            </li>
            <li>
                <a href="#" onclick="setActiveStyleSheet('magenta');" title="magenta" class="color"><img src="img/styleswitcher/magenta.png" alt="magenta"/></a>
            </li>
            <li>
                <a href="#" onclick="setActiveStyleSheet('yellowgreen');" title="yellowgreen" class="color"><img src="img/styleswitcher/yellowgreen.png" alt="yellowgreen"/></a>
            </li>
            <li>
                <a href="#" onclick="setActiveStyleSheet('orange');" title="orange" class="color"><img src="img/styleswitcher/orange.png" alt="orange"/></a>
            </li>
            <li>
                <a href="#" onclick="setActiveStyleSheet('green');" title="green" class="color"><img src="img/styleswitcher/green.png" alt="green"/></a>
            </li>
            <li>
                <a href="#" onclick="setActiveStyleSheet('yellow');" title="yellow" class="color"><img src="img/styleswitcher/yellow.png" alt="yellow"/></a>
            </li>
        </ul>

        <div id="hideSwitcher">&times;</div>
    </div>
</div>
<div id="showSwitcher" class="styleSecondColor"><i class="fa fa-cog fa-spin"></i></div>
<!-- Live Style Switcher Ends - demo only -->
<!-- Header Starts -->
<header class="header" id="navbar-collapse-toggle">
    <!-- Fixed Navigation Starts -->
    <ul class="icon-menu d-none d-lg-block revealator-slideup revealator-once revealator-delay1">
        <li class="icon-box">
            <i class="fa fa-home"></i>
            <a href="index.html">
                <h2>Home</h2>
            </a>
        </li>
        <li class="icon-box">
            <i class="fa fa-university"></i>
            <a href="about.html">
                <h2>Research</h2>
            </a>
        </li>
        <li class="icon-box">
            <i class="fa fa-briefcase"></i>
            <a href="portfolio.html">
                <h2>Portfolio</h2>
            </a>
        </li>
        <li class="icon-box">
            <i class="fa fa-photo"></i>
            <a href="contact.html">
                <h2>Hometown</h2>
            </a>
        </li>
        <li class="icon-box active">
            <i class="fa fa-comments"></i>
            <a href="blog.html">
                <h2>Blog</h2>
            </a>
        </li>
    </ul>
    <!-- Fixed Navigation Ends -->
    <!-- Mobile Menu Starts -->
    <nav role="navigation" class="d-block d-lg-none">
        <div id="menuToggle">
            <input type="checkbox" />
            <span></span>
            <span></span>
            <span></span>
            <ul class="list-unstyled" id="menu">
                <li><a href="index.html"><i class="fa fa-home"></i><span>Home</span></a></li>
                <li><a href="about.html"><i class="fa fa-university"></i><span>Research</span></a></li>
                <li><a href="portfolio.html"><i class="fa fa-folder-open"></i><span>Portfolio</span></a></li>
                <li><a href="contact.html"><i class="fa fa-photo"></i><span>Hometown</span></a></li>
                <li class="active"><a href="blog.html"><i class="fa fa-comments"></i><span>Blog</span></a></li>
            </ul>
        </div>
    </nav>
    <!-- Mobile Menu Ends -->
</header>
<!-- Header Ends -->
<!-- Page Title Starts -->
<section class="title-section text-left text-sm-center revealator-slideup revealator-once revealator-delay1">
    <h1>my <span>blog</span></h1>
    <span class="title-bg">posts</span>
</section>
<!-- Page Title Ends -->
<!-- Main Content Starts -->
<section class="main-content revealator-slideup revealator-once revealator-delay1">
    <div class="container">
        <div class="row">
            <!-- Article Starts -->
            <article class="col-12">
                <!-- Meta Starts -->
                <div class="meta open-sans-font">
                    <span><i class="fa fa-user"></i> Edison Mucllari</span>
                    <span class="date"><i class="fa fa-calendar"></i> 2021</span>
                    <span><i class="fa fa-tags"></i> convolution neural network, resnet, lenet, image processing</span>
                </div>
                <!-- Meta Ends -->
                <!-- Article Content Starts -->
                <h1 class="text-uppercase text-capitalize">Convolutional Neural Networks (CNNs)</h1>
                <img src="img/blog/blog-post-5.jpg" class="img-fluid" alt="Blog image"/>
                <div class="blog-excerpt open-sans-font pb-5">
                    
<h1>Convolutional Neural Networks (CNNs)</h1>

<div class="cnn-highlight">
    <b>What is a CNN?</b><br>
    A <b>Convolutional Neural Network (CNN)</b> is a specialized neural network architecture designed primarily for processing grid-like data such as images. CNNs use mathematical operations called <b>convolutions</b> instead of general matrix multiplication in at least one of their layers.
</div>

<h2>CNN Architecture Explained</h2>

<table class="cnn-table">
    <tr>
        <th>Layer Type</th>
        <th>Purpose</th>
        <th>Operation</th>
    </tr>
    <tr>
        <td>Convolutional Layer</td>
        <td>Feature extraction from input</td>
        <td>Applies filters to detect patterns like edges, textures, etc.</td>
    </tr>
    <tr>
        <td>Activation Layer (ReLU)</td>
        <td>Introduces non-linearity</td>
        <td>$f(x) = max(0, x)$</td>
    </tr>
    <tr>
        <td>Pooling Layer</td>
        <td>Reduces spatial dimensions</td>
        <td>Summarizes features (max or average) in a region</td>
    </tr>
    <tr>
        <td>Fully Connected Layer</td>
        <td>Classification based on features</td>
        <td>Standard neural network connections</td>
    </tr>
</table>

<div class="cnn-tip">
    <b>Key Advantages of CNNs:</b>
    <ul>
        <li><b>Parameter Sharing:</b> Same filter is applied across the entire image</li>
        <li><b>Sparse Connectivity:</b> Each output value depends only on a small local region</li>
        <li><b>Translation Invariance:</b> Can detect features regardless of their position</li>
        <li><b>Hierarchical Feature Learning:</b> Early layers learn simple features, deeper layers learn complex ones</li>
    </ul>
</div>

<h2>The Convolution Operation Explained</h2>

<div class="cnn-formula">
    <b>The 2D Convolution:</b><br>
    $$
    (I * K)(i, j) = \sum_{m}\sum_{n} I(i+m, j+n) \cdot K(m, n)
    $$
    where:
    <ul>
        <li>$I$ is the input (e.g., image)</li>
        <li>$K$ is the kernel/filter</li>
        <li>$i,j$ are the coordinates in the output</li>
        <li>$m,n$ are the coordinates in the kernel</li>
    </ul>
</div>

<div class="cnn-highlight">
    <b>How Convolution Works:</b>
    <ul>
        <li>A small filter (kernel) slides over the input</li>
        <li>At each position, element-wise multiplication and sum are computed</li>
        <li>The result forms one element in the output feature map</li>
        <li>Different filters detect different features (horizontal edges, vertical edges, etc.)</li>
    </ul>
</div>

<h2>Mathematical Details of CNN Components</h2>

<div class="cnn-formula">
    <b>1. Convolutional Layer</b><br>
    For a layer with input $X$ and kernel $W$, the output feature map $Y$ is:
    <br><br>
    $$
    Y_{i,j,k} = \sum_{m=0}^{F_h-1} \sum_{n=0}^{F_w-1} \sum_{c=0}^{C_{in}-1} X_{i+m,j+n,c} \cdot W_{m,n,c,k} + b_k
    $$
    <br>
    where:
    <ul>
        <li>$F_h, F_w$ are filter height and width</li>
        <li>$C_{in}$ is the number of input channels</li>
        <li>$b_k$ is the bias for the $k$-th filter</li>
        <li>$i,j$ are spatial coordinates in the output</li>
        <li>$k$ is the index of the output channel</li>
    </ul>
</div>

<div class="cnn-formula">
    <b>2. Pooling Layer</b><br>
    Max Pooling with a $2 \times 2$ window and stride 2:
    <br><br>
    $$
    Y_{i,j,k} = \max_{0 \leq m,n < 2} X_{2i+m, 2j+n, k}
    $$
    <br>
    Average Pooling with a $2 \times 2$ window and stride 2:
    <br><br>
    $$
    Y_{i,j,k} = \frac{1}{4} \sum_{m=0}^{1} \sum_{n=0}^{1} X_{2i+m, 2j+n, k}
    $$
</div>

<div class="cnn-formula">
    <b>3. Output Size Calculation</b><br>
    For a convolution with input size $I$, kernel size $K$, padding $P$, and stride $S$:
    <br><br>
    $$
    \text{Output Size} = \left\lfloor \frac{I - K + 2P}{S} + 1 \right\rfloor
    $$
    <br>
    where $\lfloor \rfloor$ denotes the floor operation.
</div>

<h2>Why CNNs Work: The Theory</h2>

<div class="cnn-highlight">
    <b>Key Theoretical Principles:</b>
    <ul>
        <li><b>Sparse Connectivity:</b> Each neuron connects to only a small region, reducing parameters</li>
        <li><b>Parameter Sharing:</b> Same weights used across different positions, enforcing translation equivariance</li>
        <li><b>Equivariance to Translation:</b> If input shifts, output shifts by the same amount</li>
    </ul>
</div>

<div class="cnn-formula">
    <b>Mathematical Proof of Translation Equivariance</b><br>
    Let's define a translation operator $T_u$ that shifts an input by $u$ pixels:
    <br><br>
    $$
    [T_u(I)](x) = I(x-u)
    $$
    <br>
    For a convolution operation $f(I) = I * K$, we can prove:
    <br><br>
    $$
    \begin{align}
    f(T_u(I))(x) &= [T_u(I) * K](x) \\
    &= \sum_y T_u(I)(y) \cdot K(x-y) \\
    &= \sum_y I(y-u) \cdot K(x-y) \\
    \end{align}
    $$
    <br>
    With substitution $z = y-u$:
    <br><br>
    $$
    \begin{align}
    f(T_u(I))(x) &= \sum_z I(z) \cdot K(x-(z+u)) \\
    &= \sum_z I(z) \cdot K((x-u)-z) \\
    &= [I * K](x-u) \\
    &= T_u(f(I))(x)
    \end{align}
    $$
    <br>
    This proves that $f(T_u(I)) = T_u(f(I))$, demonstrating translation equivariance.
</div>

<h2>Famous CNN Architectures</h2>

<table class="cnn-table">
    <tr>
        <th>Architecture</th>
        <th>Year</th>
        <th>Key Innovation</th>
        <th>Performance</th>
    </tr>
    <tr>
        <td>LeNet-5</td>
        <td>1998</td>
        <td>First successful CNN for digit recognition</td>
        <td>~99% on MNIST</td>
    </tr>
    <tr>
        <td>AlexNet</td>
        <td>2012</td>
        <td>ReLU, Dropout, GPU implementation</td>
        <td>Top-5 error: 15.3% on ImageNet</td>
    </tr>
    <tr>
        <td>VGGNet</td>
        <td>2014</td>
        <td>Small filters (3×3), deeper network</td>
        <td>Top-5 error: 7.3% on ImageNet</td>
    </tr>
    <tr>
        <td>ResNet</td>
        <td>2015</td>
        <td>Skip connections to solve vanishing gradient</td>
        <td>Top-5 error: 3.57% on ImageNet</td>
    </tr>
</table>

<div class="cnn-tip">
    <b>ResNet's Skip Connection:</b>
    <p>One of the most important innovations in CNN architecture was the residual block in ResNet, which can be expressed as:</p>
    $$
    y = F(x, \{W_i\}) + x
    $$
    <p>where $F$ is a residual mapping to be learned and $x$ is the identity mapping (skip connection).</p>
</div>

<h2>Backpropagation in CNNs</h2>

<div class="cnn-formula">
    <b>Gradient Computation for Convolutional Layers</b><br>
    For a convolutional layer with weights $W$ and input $X$, the gradient of the loss $L$ with respect to $W$ is:
    <br><br>
    $$
    \frac{\partial L}{\partial W_{m,n,c,k}} = \sum_{i,j} \frac{\partial L}{\partial Y_{i,j,k}} \cdot X_{i+m,j+n,c}
    $$
    <br>
    And the gradient with respect to the input is:
    <br><br>
    $$
    \frac{\partial L}{\partial X_{i,j,c}} = \sum_{k} \sum_{m,n} \frac{\partial L}{\partial Y_{i-m,j-n,k}} \cdot W_{m,n,c,k}
    $$
</div>

<h2>Why CNNs Excel at Image Processing</h2>

<div class="cnn-highlight">
    <b>Biological Inspiration:</b>
    <p>CNNs are inspired by the visual cortex in animals. The receptive fields of neurons in the visual cortex are localized, and different neurons respond to visual stimuli in restricted regions. Similarly, CNN filters respond to local patterns in their receptive fields.</p>
</div>

<div class="cnn-tip">
    <b>Hierarchical Feature Learning:</b>
    <ul>
        <li>Early layers: Detect simple features like edges and corners</li>
        <li>Middle layers: Combine simple features into more complex patterns like textures</li>
        <li>Deep layers: Recognize high-level concepts like objects and faces</li>
    </ul>
    <p>This hierarchical structure allows CNNs to build complex representations from simple building blocks.</p>
</div>

<h2>Practical Considerations</h2>

<div class="cnn-warning">
    <b>Common Challenges:</b>
    <ul>
        <li><b>Overfitting:</b> Especially with limited data</li>
        <li><b>Computational Cost:</b> Training deep CNNs requires significant resources</li>
        <li><b>Vanishing/Exploding Gradients:</b> Can make training very deep networks difficult</li>
    </ul>
</div>

<div class="cnn-tip">
    <b>Best Practices:</b>
    <ul>
        <li><b>Data Augmentation:</b> Artificially increase training data by applying transformations</li>
        <li><b>Batch Normalization:</b> Normalize activations to stabilize training</li>
        <li><b>Transfer Learning:</b> Use pre-trained models and fine-tune on specific tasks</li>
        <li><b>Regularization:</b> Apply dropout or L2 regularization to prevent overfitting</li>
    </ul>
</div>

<h2>References</h2>
<ul>
    <li>
        LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). <b>Gradient-based learning applied to document recognition</b>. <i>Proceedings of the IEEE</i>, 86(11), 2278-2324.
    </li>
    <li>
        Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). <b>ImageNet classification with deep convolutional neural networks</b>. <i>NeurIPS</i>.
    </li>
    <li>
        He, K., Zhang, X., Ren, S., & Sun, J. (2016). <b>Deep residual learning for image recognition</b>. <i>CVPR</i>.
    </li>
    <li>
        Goodfellow, I., Bengio, Y., & Courville, A. (2016). <b>Deep Learning</b>. MIT Press.
    </li>
</ul>

                </div>
                <!-- Article Content Ends -->
            </article>
            <!-- Article Ends -->
        </div>
    </div>
</section>
<!-- Template JS Files -->
<script src="js/jquery-3.5.0.min.js"></script>
<script src="js/styleswitcher.js"></script>
<script src="js/preloader.min.js"></script>
<script src="js/fm.revealator.jquery.min.js"></script>
<script src="js/imagesloaded.pkgd.min.js"></script>
<script src="js/masonry.pkgd.min.js"></script>
<script src="js/classie.js"></script>
<script src="js/cbpGridGallery.js"></script>
<script src="js/jquery.hoverdir.js"></script>
<script src="js/popper.min.js"></script>
<script src="js/bootstrap.js"></script>
<script src="js/custom.js"></script>

</body>
</html>