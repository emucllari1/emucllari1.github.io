<!DOCTYPE html>
<html lang="en">


<head>
    <meta charset="utf-8">
    <title>Edison's Blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" type="image/jpg" href="favicon.ico"/>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

    <!-- Template Google Fonts -->
    <link href="https://fonts.googleapis.com/css?family=Poppins:400,400i,500,500i,600,600i,700,700i,800,800i,900,900i" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,400i,600,600i,700" rel="stylesheet">

    <!-- Template CSS Files -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/preloader.min.css" rel="stylesheet">
    <link href="css/circle.css" rel="stylesheet">
    <link href="css/font-awesome.min.css" rel="stylesheet">
    <link href="css/fm.revealator.jquery.min.css" rel="stylesheet">
    <link href="css/style.css" rel="stylesheet">

    <!-- CSS Skin File -->
    <link href="css/skins/green.css" rel="stylesheet">

    <!-- Live Style Switcher - demo only -->
    <link rel="alternate stylesheet" type="text/css" title="blue" href="css/skins/blue.css" />
    <link rel="alternate stylesheet" type="text/css" title="green" href="css/skins/green.css" />
    <link rel="alternate stylesheet" type="text/css" title="yellow" href="css/skins/yellow.css" />
    <link rel="alternate stylesheet" type="text/css" title="blueviolet" href="css/skins/blueviolet.css" />
    <link rel="alternate stylesheet" type="text/css" title="goldenrod" href="css/skins/goldenrod.css" />
    <link rel="alternate stylesheet" type="text/css" title="magenta" href="css/skins/magenta.css" />
    <link rel="alternate stylesheet" type="text/css" title="orange" href="css/skins/orange.css" />
    <link rel="alternate stylesheet" type="text/css" title="purple" href="css/skins/purple.css" />
    <link rel="alternate stylesheet" type="text/css" title="red" href="css/skins/red.css" />
    <link rel="alternate stylesheet" type="text/css" title="yellowgreen" href="css/skins/yellowgreen.css" />
    <link rel="stylesheet" type="text/css" href="css/styleswitcher.css" />

    <script src="js/modernizr.custom.js"></script>

    <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']], // Delimiters for inline math
        displayMath: [['$$', '$$'], ['\\[', '\\]']], // Delimiters for display math
        processEscapes: true // Allows \$ to be treated as text
      },
      svg: {
        fontCache: 'global' // Improves rendering speed
      }
    };
    </script>
    <script id="MathJax-script" async
            src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>













<style>
    .gan-highlight {
        background: #e3f2fd;
        border-left: 6px solid #1976d2;
        padding: 14px;
        margin: 24px 0;
        border-radius: 8px;
    }
    .gan-formula {
        background: #fffde7;
        border-left: 6px solid #fbc02d;
        padding: 14px;
        margin: 24px 0;
        border-radius: 8px;
        font-size: 1.09em;
    }
    .gan-tip {
        background: #e8f5e9;
        border-left: 6px solid #388e3c;
        padding: 14px;
        margin: 24px 0;
        border-radius: 8px;
    }
    .gan-warning {
        background: #fff3e0;
        border-left: 6px solid #f57c00;
        padding: 14px;
        margin: 24px 0;
        border-radius: 8px;
    }
    .gan-table {
        border-collapse: collapse;
        width: 100%;
        margin: 20px 0;
    }
    .gan-table th, .gan-table td {
        border: 1px solid #bdbdbd;
        padding: 10px;
        text-align: left;
    }
    .gan-table th {
        background: #f0f4c3;
    }
    .gan-table tr:nth-child(even) {
        background: #f9fbe7;
    }
</style>




















</head>

<body class="blog-post light">
<!-- Live Style Switcher Starts - demo only -->
<div id="switcher" class="">
    <div class="content-switcher">
        <h4>STYLE SWITCHER</h4>
        <ul>
            <li>
                <a href="#" onclick="setActiveStyleSheet('purple');" title="purple" class="color"><img src="img/styleswitcher/purple.png" alt="purple"/></a>
            </li>
            <li>
                <a href="#" onclick="setActiveStyleSheet('red');" title="red" class="color"><img src="img/styleswitcher/red.png" alt="red"/></a>
            </li>
            <li>
                <a href="#" onclick="setActiveStyleSheet('blueviolet');" title="blueviolet" class="color"><img src="img/styleswitcher/blueviolet.png" alt="blueviolet"/></a>
            </li>
            <li>
                <a href="#" onclick="setActiveStyleSheet('blue');" title="blue" class="color"><img src="img/styleswitcher/blue.png" alt="blue"/></a>
            </li>
            <li>
                <a href="#" onclick="setActiveStyleSheet('goldenrod');" title="goldenrod" class="color"><img src="img/styleswitcher/goldenrod.png" alt="goldenrod"/></a>
            </li>
            <li>
                <a href="#" onclick="setActiveStyleSheet('magenta');" title="magenta" class="color"><img src="img/styleswitcher/magenta.png" alt="magenta"/></a>
            </li>
            <li>
                <a href="#" onclick="setActiveStyleSheet('yellowgreen');" title="yellowgreen" class="color"><img src="img/styleswitcher/yellowgreen.png" alt="yellowgreen"/></a>
            </li>
            <li>
                <a href="#" onclick="setActiveStyleSheet('orange');" title="orange" class="color"><img src="img/styleswitcher/orange.png" alt="orange"/></a>
            </li>
            <li>
                <a href="#" onclick="setActiveStyleSheet('green');" title="green" class="color"><img src="img/styleswitcher/green.png" alt="green"/></a>
            </li>
            <li>
                <a href="#" onclick="setActiveStyleSheet('yellow');" title="yellow" class="color"><img src="img/styleswitcher/yellow.png" alt="yellow"/></a>
            </li>
        </ul>

        <div id="hideSwitcher">&times;</div>
    </div>
</div>
<div id="showSwitcher" class="styleSecondColor"><i class="fa fa-cog fa-spin"></i></div>
<!-- Live Style Switcher Ends - demo only -->
<!-- Header Starts -->
<header class="header" id="navbar-collapse-toggle">
    <!-- Fixed Navigation Starts -->
    <ul class="icon-menu d-none d-lg-block revealator-slideup revealator-once revealator-delay1">
        <li class="icon-box">
            <i class="fa fa-home"></i>
            <a href="index.html">
                <h2>Home</h2>
            </a>
        </li>
        <li class="icon-box">
            <i class="fa fa-university"></i>
            <a href="about.html">
                <h2>Research</h2>
            </a>
        </li>
        <li class="icon-box">
            <i class="fa fa-briefcase"></i>
            <a href="portfolio.html">
                <h2>Portfolio</h2>
            </a>
        </li>
        <li class="icon-box">
            <i class="fa fa-photo"></i>
            <a href="contact.html">
                <h2>Hometown</h2>
            </a>
        </li>
        <li class="icon-box active">
            <i class="fa fa-comments"></i>
            <a href="blog.html">
                <h2>Blog</h2>
            </a>
        </li>
    </ul>
    <!-- Fixed Navigation Ends -->
    <!-- Mobile Menu Starts -->
    <nav role="navigation" class="d-block d-lg-none">
        <div id="menuToggle">
            <input type="checkbox" />
            <span></span>
            <span></span>
            <span></span>
            <ul class="list-unstyled" id="menu">
                <li><a href="index.html"><i class="fa fa-home"></i><span>Home</span></a></li>
                <li><a href="about.html"><i class="fa fa-university"></i><span>Research</span></a></li>
                <li><a href="portfolio.html"><i class="fa fa-folder-open"></i><span>Portfolio</span></a></li>
                <li><a href="contact.html"><i class="fa fa-photo"></i><span>Hometown</span></a></li>
                <li class="active"><a href="blog.html"><i class="fa fa-comments"></i><span>Blog</span></a></li>
            </ul>
        </div>
    </nav>
    <!-- Mobile Menu Ends -->
</header>
<!-- Header Ends -->
<!-- Page Title Starts -->
<section class="title-section text-left text-sm-center revealator-slideup revealator-once revealator-delay1">
    <h1>my <span>blog</span></h1>
    <span class="title-bg">posts</span>
</section>
<!-- Page Title Ends -->
<!-- Main Content Starts -->
<section class="main-content revealator-slideup revealator-once revealator-delay1">
    <div class="container">
        <div class="row">
            <!-- Article Starts -->
            <article class="col-12">
                <!-- Meta Starts -->
                <div class="meta open-sans-font">
                    <span><i class="fa fa-user"></i> Edison Mucllari</span>
                    <span class="date"><i class="fa fa-calendar"></i> 2021</span>
                    <span><i class="fa fa-tags"></i> wasserstein GAN</span>
                </div>
                <!-- Meta Ends -->
                <!-- Article Content Starts -->
                <h1 class="text-uppercase text-capitalize">Wasserstein Generative Adversarial Network</h1>
                <img src="img/blog/blog-post-4.jpg" class="img-fluid" alt="Blog image"/>
                <div class="blog-excerpt open-sans-font pb-5">
                    








<h1>Wasserstein Generative Adversarial Networks (WGANs)</h1>

<div class="gan-highlight">
    <b>What is a Wasserstein GAN?</b><br>
    A <b>Wasserstein GAN (WGAN)</b> is an improvement to the original GAN that uses the Wasserstein distance (also called Earth Mover's distance) instead of Jensen-Shannon divergence to measure the difference between the real and generated data distributions. This leads to more stable training and better quality results.
</div>

<h2>Why Traditional GANs Have Problems</h2>

<div class="gan-warning">
    <b>Issues with Standard GANs:</b>
    <ul>
        <li><b>Mode collapse:</b> The generator produces a limited variety of samples</li>
        <li><b>Vanishing gradients:</b> When the discriminator becomes too good, the generator stops learning</li>
        <li><b>Training instability:</b> Oscillations instead of convergence</li>
        <li><b>Lack of correlation:</b> Loss doesn't correlate well with output quality</li>
    </ul>
</div>

<h2>The Limitations of JS Divergence</h2>

<div class="gan-formula">
    <b>The Problem with Jensen-Shannon Divergence:</b><br>
    When two distributions have non-overlapping supports (which happens early in GAN training), the JS divergence returns a constant value:<br><br>
    
    $$
    \text{JSD}(P_r || P_g) = \log 2
    $$
    
    <br>
    This leads to uninformative gradients for the generator, causing training difficulties.
</div>

<h2>Optimal Transport and Wasserstein Distance</h2>

<div class="gan-highlight">
    <b>What is Optimal Transport?</b><br>
    Optimal Transport is a mathematical framework for comparing probability distributions by finding the most efficient way to transform one distribution into another, minimizing a "transportation cost."
</div>

<div class="gan-formula">
    <b>The Wasserstein-1 Distance (Earth Mover's Distance):</b><br>
    
    $$
    W_1(P_r, P_g) = \inf_{\gamma \in \Pi(P_r, P_g)} \mathbb{E}_{(x,y) \sim \gamma} \left[ \|x - y\| \right]
    $$
    
    <br>
    Where:
    <ul>
        <li>$\Pi(P_r, P_g)$ is the set of all joint distributions $\gamma(x,y)$ whose marginals are $P_r$ and $P_g$</li>
        <li>$\|x - y\|$ represents the cost of moving a unit of mass from $x$ to $y$</li>
    </ul>
    <b>This can be interpreted as finding the optimal way to "move earth" from one distribution to another with minimal effort.</b>
</div>

<div class="gan-tip">
    <b>Why Wasserstein is Better:</b>
    <ul>
        <li>Provides meaningful gradients even when distributions don't overlap</li>
        <li>Gives a continuous measure of distance between distributions</li>
        <li>The Wasserstein loss correlates well with generated sample quality</li>
    </ul>
</div>

<h2>Kantorovich-Rubinstein Duality</h2>

<div class="gan-formula">
    <b>The Dual Form of the Wasserstein Distance:</b><br>
    The Wasserstein distance can be rewritten using Kantorovich-Rubinstein duality as:
    
    $$
    W_1(P_r, P_g) = \sup_{f \in \text{Lip}_1} \mathbb{E}_{x \sim P_r}[f(x)] - \mathbb{E}_{x \sim P_g}[f(x)]
    $$
    
    <br>
    Where $\text{Lip}_1$ is the set of all 1-Lipschitz functions (functions where $|f(x) - f(y)| \leq |x - y|$ for all $x, y$).
</div>

<div class="gan-formula">
<b>Proof of Kantorovich-Rubinstein Duality</b><br>
Let's show the equivalence between the primal form:
$$
W_1(P_r, P_g) = \inf_{\gamma \in \Pi(P_r, P_g)} \mathbb{E}_{(x,y) \sim \gamma} \left[ \|x - y\| \right]
$$

And the dual form:
$$
W_1(P_r, P_g) = \sup_{f \in \text{Lip}_1} \mathbb{E}_{x \sim P_r}[f(x)] - \mathbb{E}_{x \sim P_g}[f(x)]
$$

The proof relies on linear programming duality. The primal problem can be formulated as a linear program over coupling measures, and the dual involves optimizing over the space of 1-Lipschitz functions.

For any coupling $\gamma \in \Pi(P_r, P_g)$ and any 1-Lipschitz function $f$:
$$
\mathbb{E}_{x \sim P_r}[f(x)] - \mathbb{E}_{x \sim P_g}[f(x)] = \int f(x)dP_r(x) - \int f(y)dP_g(y)
$$

Since $\gamma$ has marginals $P_r$ and $P_g$:
$$
\int f(x)dP_r(x) - \int f(y)dP_g(y) = \iint f(x)d\gamma(x,y) - \iint f(y)d\gamma(x,y)
$$
$$
= \iint [f(x) - f(y)]d\gamma(x,y)
$$

Since $f$ is 1-Lipschitz, $f(x) - f(y) \leq \|x - y\|$, so:
$$
\iint [f(x) - f(y)]d\gamma(x,y) \leq \iint \|x - y\|d\gamma(x,y) = \mathbb{E}_{(x,y) \sim \gamma}[\|x - y\|]
$$

This shows that the dual objective is bounded by the primal objective. The equality can be proved by carefully constructing optimal solutions.
</div>

<h2>From Theory to Practice: WGAN Architecture</h2>

<table class="gan-table">
    <tr>
        <th>Standard GAN</th>
        <th>Wasserstein GAN</th>
    </tr>
    <tr>
        <td>Discriminator outputs probabilities (0-1)</td>
        <td>Critic outputs real numbers (unbounded)</td>
    </tr>
    <tr>
        <td>Uses sigmoid in final layer</td>
        <td>No sigmoid in final layer</td>
    </tr>
    <tr>
        <td>Log loss for training</td>
        <td>Wasserstein loss (difference of expectations)</td>
    </tr>
    <tr>
        <td>No explicit constraint on discriminator</td>
        <td>Weight clipping or gradient penalty for Lipschitz constraint</td>
    </tr>
</table>

<div class="gan-formula">
    <b>The WGAN Objective Function:</b><br>
    
    $$
    \min_G \max_{D \in \mathcal{D}} \mathbb{E}_{x \sim P_r}[D(x)] - \mathbb{E}_{z \sim p(z)}[D(G(z))]
    $$
    
    <br>
    Where:
    <ul>
        <li>$D$ is the critic (renamed from discriminator) constrained to be 1-Lipschitz</li>
        <li>$G$ is the generator</li>
        <li>$z$ is random noise</li>
        <li>$\mathcal{D}$ is the set of 1-Lipschitz functions</li>
    </ul>
</div>

<h2>Enforcing the Lipschitz Constraint</h2>

<div class="gan-warning">
    <b>Two Main Approaches:</b>
    <ol>
        <li><b>Weight Clipping (Original WGAN):</b> Clip weights to a small range like [-0.01, 0.01]</li>
        <li><b>Gradient Penalty (WGAN-GP):</b> Add a penalty term to enforce gradient norm of 1</li>
    </ol>
</div>

<div class="gan-formula">
    <b>WGAN-GP Objective:</b><br>
    
    $$
    L = \mathbb{E}_{\tilde{x} \sim P_g}[D(\tilde{x})] - \mathbb{E}_{x \sim P_r}[D(x)] + \lambda \mathbb{E}_{\hat{x} \sim P_{\hat{x}}}[(||\nabla_{\hat{x}} D(\hat{x})||_2 - 1)^2]
    $$
    
    <br>
    Where:
    <ul>
        <li>$\hat{x}$ are points sampled uniformly along lines between pairs of points from $P_r$ and $P_g$</li>
        <li>$\lambda$ is the gradient penalty coefficient (usually 10)</li>
    </ul>
</div>

<div class="gan-formula">
<b>Detailed Explanation of the Gradient Penalty</b><br>
The 1-Lipschitz constraint requires that:
$$
|D(x) - D(y)| \leq |x - y| \quad \text{for all } x, y
$$

This is equivalent to requiring the gradient norm to be at most 1 everywhere:
$$
||\nabla_x D(x)||_2 \leq 1 \quad \text{for all } x
$$

The WGAN-GP enforces this by penalizing the model when the gradient norm deviates from 1 at randomly sampled points. The samples are taken along straight lines between real and generated data points:
$$
\hat{x} = t \cdot x + (1-t) \cdot \tilde{x}
$$
where $t \sim U[0,1]$, $x \sim P_r$, and $\tilde{x} \sim P_g$.

The penalty term is:
$$
\lambda \cdot \mathbb{E}_{\hat{x}}[(||\nabla_{\hat{x}} D(\hat{x})||_2 - 1)^2]
$$

This penalty forces the gradient norm to be close to 1 along important regions of the data space, effectively enforcing the Lipschitz constraint without explicitly clipping weights.
</div>

<h2>The WGAN Training Algorithm</h2>

<div class="gan-highlight">
    <b>WGAN Training Loop:</b>
    <ol>
        <li>For each critic training step:
            <ul>
                <li>Sample real data batch $\{x^{(i)}\}_{i=1}^m$ from real data distribution $P_r$</li>
                <li>Sample noise batch $\{z^{(i)}\}_{i=1}^m$ from noise distribution $p(z)$</li>
                <li>Generate fake data $\{\tilde{x}^{(i)} = G(z^{(i)})\}_{i=1}^m$</li>
                <li>Update critic by ascending its stochastic gradient:
                    $$\nabla_{\theta_D} \frac{1}{m} \sum_{i=1}^m [D(x^{(i)}) - D(G(z^{(i)}))]$$</li>
                <li>Apply weight clipping to critic parameters: $w \leftarrow \text{clip}(w, -c, c)$ (Original WGAN)</li>
                <li>OR apply gradient penalty (WGAN-GP)</li>
            </ul>
        </li>
        <li>For each generator training step:
            <ul>
                <li>Sample noise batch $\{z^{(i)}\}_{i=1}^m$ from noise distribution $p(z)$</li>
                <li>Update generator by descending its stochastic gradient:
                    $$\nabla_{\theta_G} \frac{1}{m} \sum_{i=1}^m [-D(G(z^{(i)}))]$$</li>
            </ul>
        </li>
    </ol>
</div>

<div class="gan-tip">
    <b>Key Implementation Details:</b>
    <ul>
        <li>Train the critic more frequently than the generator (often 5:1 ratio)</li>
        <li>Use RMSProp or Adam with a low learning rate (e.g., 0.00005)</li>
        <li>Avoid using batch normalization in the critic (can use layer normalization instead)</li>
        <li>WGAN-GP tends to be more stable than the original weight clipping approach</li>
    </ul>
</div>

<h2>WGAN Benefits and Applications</h2>

<div class="gan-highlight">
    <b>Advantages of WGANs:</b>
    <ul>
        <li><b>More stable training:</b> Less sensitive to architectural choices and hyperparameters</li>
        <li><b>Meaningful loss:</b> The Wasserstein distance correlates well with generated sample quality</li>
        <li><b>Reduced mode collapse:</b> Better coverage of the data distribution</li>
        <li><b>Improved convergence:</b> Clearer signals when training is complete</li>
    </ul>
</div>

<h2>Mathematical Comparison of Distance Metrics</h2>

<div class="gan-formula">
    <b>Comparing Different Probability Divergences/Distances:</b><br>
    
    <ul>
        <li><b>KL Divergence:</b> $D_{KL}(P || Q) = \int P(x) \log \frac{P(x)}{Q(x)} dx$</li>
        <li><b>JS Divergence:</b> $D_{JS}(P || Q) = \frac{1}{2} D_{KL}(P || M) + \frac{1}{2} D_{KL}(Q || M)$ where $M = \frac{1}{2}(P+Q)$</li>
        <li><b>Wasserstein Distance:</b> $W_1(P, Q) = \inf_{\gamma \in \Pi(P, Q)} \mathbb{E}_{(x,y) \sim \gamma} \left[ \|x - y\| \right]$</li>
    </ul>
    
    <b>Key Differences:</b>
    <ul>
        <li>KL and JS divergences are not well-defined when distributions don't overlap</li>
        <li>Wasserstein distance gives meaningful values and gradients even for non-overlapping distributions</li>
        <li>Wasserstein distance respects the underlying geometry of the space</li>
    </ul>
</div>

<div class="gan-formula">
<b>Visual Intuition: Why Wasserstein Works Better</b><br>

Consider two 1D Gaussian distributions $P$ and $Q$ moving away from each other:

When they have significant overlap:
- KL: Defined, provides useful gradients
- JS: Defined, provides useful gradients
- W1: Defined, provides useful gradients

As they move further apart with minimal overlap:
- KL: Approaches infinity (extremely high gradients)
- JS: Approaches $\log 2$ (vanishing gradients)
- W1: Equals the distance between distributions (stable gradients)

When they have no overlap:
- KL: Infinite (undefined)
- JS: Constant $\log 2$ (zero gradients)
- W1: Exactly the distance between means (meaningful, useful gradients)

This is why Wasserstein distance provides a more stable learning signal throughout the entire training process.
</div>

<h2>Advanced Topics: Extensions of WGAN</h2>

<table class="gan-table">
    <tr>
        <th>Extension</th>
        <th>Key Idea</th>
        <th>Benefit</th>
    </tr>
    <tr>
        <td>WGAN-GP</td>
        <td>Gradient penalty instead of weight clipping</td>
        <td>Better Lipschitz enforcement, more stable training</td>
    </tr>
    <tr>
        <td>WGAN-LP</td>
        <td>Gradient penalty only where gradient > 1</td>
        <td>Less restrictive constraint, faster training</td>
    </tr>
    <tr>
        <td>Spectral Normalization</td>
        <td>Normalize weights to control Lipschitz constant</td>
        <td>Efficient Lipschitz enforcement, stable training</td>
    </tr>
    <tr>
        <td>WGAN-div</td>
        <td>Alternative regularization of critic gradients</td>
        <td>Improved sample quality and training stability</td>
    </tr>
</table>

<h2>Practical Implementation Advice</h2>

<div class="gan-tip">
    <b>Tips for Implementing WGANs:</b>
    <ul>
        <li>Use the WGAN-GP variant for better stability</li>
        <li>Choose a gradient penalty coefficient of 10</li>
        <li>Remove batch normalization from the critic (use layer norm or instance norm)</li>
        <li>Train the critic 5 times for each generator update</li>
        <li>Use the Adam optimizer with a learning rate of 0.0001 and betas=(0.5, 0.9)</li>
        <li>Monitor the Wasserstein estimate (critic loss) to gauge training progress</li>
    </ul>
</div>

<h2>References</h2>
<ul>
    <li>
        Arjovsky, M., Chintala, S., & Bottou, L. (2017). <b>Wasserstein Generative Adversarial Networks</b>. <i>International Conference on Machine Learning (ICML)</i>.
    </li>
</ul>
















                </div>
                <!-- Article Content Ends -->
            </article>
            <!-- Article Ends -->
        </div>
    </div>
</section>
<!-- Template JS Files -->
<script src="js/jquery-3.5.0.min.js"></script>
<script src="js/styleswitcher.js"></script>
<script src="js/preloader.min.js"></script>
<script src="js/fm.revealator.jquery.min.js"></script>
<script src="js/imagesloaded.pkgd.min.js"></script>
<script src="js/masonry.pkgd.min.js"></script>
<script src="js/classie.js"></script>
<script src="js/cbpGridGallery.js"></script>
<script src="js/jquery.hoverdir.js"></script>
<script src="js/popper.min.js"></script>
<script src="js/bootstrap.js"></script>
<script src="js/custom.js"></script>

</body>


</html>
